{
  "permissions": {
    "allow": [
      "Bash(curl -s \"https://taskforce-purple-api.dev-glasgowshipyard.workers.dev/api/members\")",
      "Bash(wrangler kv:key get:*)",
      "Bash(wrangler kv key get:*)",
      "Bash(wrangler kv key list:*)",
      "Bash(git add:*)",
      "Bash(git commit -m \"$(cat <<''EOF''\nAdd priority queue processing for missing largeDonorDonations\n\n- Processes priority_missing_queue before normal batch processing\n- Handles 2 members per run (14 FEC calls, within rate limits)\n- Auto-deletes queue when complete\n- Fixes 160 members missing largeDonorDonations data\n\nðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>\nEOF\n)\")",
      "Bash(wrangler deploy:*)",
      "Bash(wrangler logout:*)",
      "Bash(wrangler login:*)",
      "Bash(wrangler deployments list:*)",
      "Bash(curl:*)",
      "Bash(wrangler deployments view:*)",
      "Bash(wrangler kv namespace:*)",
      "Bash(git commit:*)",
      "Bash(wrangler kv key put:*)",
      "Bash(wrangler kv:*)",
      "Read(//Users/zielinski/**)",
      "Read(//private/tmp/**)",
      "Bash(cat:*)",
      "Bash(gh issue list:*)",
      "Bash(python3:*)",
      "WebFetch(domain:api.open.fec.gov)",
      "Bash(gh issue create --title \"ENHANCEMENT: Itemized Donor Concentration Analysis (Schedule A Transaction Data)\" --label \"enhancement\" --body \"$(cat <<''EOF''\n## Problem Statement\n\nCurrent tier calculations treat all itemized donations (>$200) equally, but this masks critical differences in donor concentration. Two members can have identical itemized percentages (~41%) while having drastically different funding models:\n\n- **Member A**: 41% itemized from ~13,000 middle-class donors giving $200-500 each\n- **Member B**: 41% itemized from ~2,000 wealthy donors giving $2,000-3,000 each\n\nUnder the current system, both appear identical. **We need transparency into who is actually funding our representatives.**\n\n## Current Limitation\n\nWe only have aggregate totals from FEC summary data:\n- Total itemized donations: $4,200,000\n- Total grassroots donations: $2,100,000\n- **We cannot see**: How many unique donors? How concentrated? Top 10 donors = what %?\n\nSome candidates appear to have broad individual support but may actually be funded by a small group of wealthy donors. **The data exists in FEC Schedule Aâ€”we just need to fetch it.**\n\n## Proposed Solution\n\n### Architecture: Separate Worker for Transaction Analysis\n\nCreate a dedicated Cloudflare Worker (`taskforce-purple-itemized`) that:\n\n1. **Runs on scheduled cron** (every 1-5 minutes)\n2. **Processes 1-2 members per run** (stays within free tier 10ms CPU limit)\n3. **Fetches full Schedule A transaction data** from FEC API\n4. **Stores raw transaction data** in dedicated KV namespace\n5. **Calculates concentration metrics** for tier calculations\n\n### What We Get from Schedule A Data\n\nOnce we fetch all itemized transactions, we have:\n\n- âœ… **Every individual contributor name** (deduplicate for unique donor count)\n- âœ… **Every transaction amount** (calculate distribution, concentration)\n- âœ… **Dates, locations, employer info** (future analysis potential)\n- âœ… **Top donor concentration** (top 10 donors = X% of total itemized)\n- âœ… **Gini coefficient** (measure of donation inequality)\n- âœ… **Repeat donor patterns** (one-time vs sustained support)\n- âœ… **Average donation size** (proxy for wealth concentration)\n\n**Most importantly:** Once we have the raw data stored, we can run ANY analysis without re-fetching from FEC.\n\n### Free Tier Compliance\n\n**Resource requirements:**\n- FEC API calls: ~10,700 total (free with enhanced rate limit via email)\n- Cloudflare Worker CPU: 10ms/request on free tier Ã— 1-2 members/run = âœ… compliant\n- KV storage: ~535 MB raw transactions (fits in 1 GB free tier)\n- KV writes: ~535 members = 535 writes (under 1k/day limit)\n- Processing time: Initial build = 4-22 hours via scheduled cron\n\n**Why this works:** Instead of one giant CPU-intensive job, we break it into 268+ tiny jobs that each fit in free tier limits.\n\n### Storage Strategy\n\n**Option 1: Raw Transaction Data (RECOMMENDED)**\n- Store every transaction: `{contributor_name, amount, date, employer, ...}`\n- Size: ~535 MB (53.5% of free KV tier)\n- **Benefit**: Can calculate ANY metric in the future without re-fetching\n- **Future-proof**: New concentration algorithms, new analyses, all possible\n\n**Option 2: Aggregated Stats Only**\n- Store only: `{uniqueDonors, avgDonation, topDonorPercent, ...}`\n- Size: ~2.7 MB\n- **Drawback**: Locked into these metrics forever, need to re-fetch for new analysis\n\n**Recommendation**: Store raw data. It''s still well within free tier and gives us complete flexibility.\n\n### KV Structure\n\n**Namespace**: `ITEMIZED_ANALYSIS`\n\n**Keys**:\n- `transactions:{bioguideId}` - Array of all itemized transactions\n- `stats:{bioguideId}` - Pre-calculated concentration metrics\n- `processing_queue` - List of members needing analysis\n- `last_processed` - Tracking for scheduled cron\n\n**Example transaction record**:\n```json\n{\n  \"contributor_name\": \"JOHN SMITH\",\n  \"amount\": 2700,\n  \"date\": \"2024-03-15\",\n  \"employer\": \"TECH CORP\",\n  \"occupation\": \"SOFTWARE ENGINEER\",\n  \"city\": \"SAN FRANCISCO\",\n  \"state\": \"CA\"\n}\n```\n\n**Example stats record**:\n```json\n{\n  \"bioguideId\": \"X000001\",\n  \"totalItemized\": 4200000,\n  \"transactionCount\": 2809,\n  \"uniqueDonors\": 1847,\n  \"avgDonation\": 1495,\n  \"medianDonation\": 1000,\n  \"top10DonorPercent\": 15.3,\n  \"top100DonorPercent\": 42.1,\n  \"giniCoefficient\": 0.67,\n  \"lastUpdated\": \"2025-10-16T12:00:00Z\"\n}\n```\n\n### Implementation Plan\n\n1. **Create new Worker** (`taskforce-purple-itemized`)\n   - Schedule cron trigger (every 1-5 minutes)\n   - Process 1-2 members per invocation\n   - Fetch all Schedule A transactions (paginated)\n   - Store in KV\n\n2. **Create KV namespace** (`ITEMIZED_ANALYSIS`)\n   - Separate from main member data\n   - Dedicated to transaction storage\n\n3. **Update main Worker** to read itemized stats\n   - Join with member data for tier calculation\n   - Use concentration metrics in tier penalties\n\n4. **Initial data population**\n   - Queue all 535 members\n   - Process via scheduled cron (4-22 hours)\n   - Track progress in processing_queue\n\n5. **Ongoing updates**\n   - Re-fetch quarterly (matches threshold recalculation)\n   - Priority queue for members with recent activity\n\n### Metrics for Tier Calculation\n\n**Concentration Score**:\n- If top 10 donors > 25% of itemized â†’ High concentration penalty\n- If top 100 donors > 60% of itemized â†’ Medium concentration penalty\n- If unique donors < 500 â†’ Low donor base penalty\n- If avg donation > $2,000 â†’ Wealth concentration penalty\n\n**Example tier impact**:\n- Member with 41% itemized, 2,000 wealthy donors â†’ **Tier drops** (concentrated)\n- Member with 41% itemized, 13,000 middle-class donors â†’ **Tier maintains** (broad)\n\nThis reveals the **actual** funding model transparency.\n\n## Benefits\n\n1. **Transparency**: See who actually funds representatives\n2. **Accuracy**: Distinguish concentrated vs broad individual support\n3. **Future-proof**: Raw data enables any future analysis\n4. **Free tier compliant**: Scheduled processing fits all limits\n5. **Scalable**: Easy to add new metrics without re-fetching\n6. **Defensible**: Hard FEC data, not estimates or intuition\n\n## Next Steps\n\n1. Get enhanced FEC API rate limit (email request, free)\n2. Create `taskforce-purple-itemized` worker repository\n3. Set up `ITEMIZED_ANALYSIS` KV namespace\n4. Implement scheduled cron processor\n5. Test with small batch (10-20 members)\n6. Deploy and populate all 535 members\n7. Update tier calculation with concentration penalties\n\n---\n\n**This is the missing piece for true campaign finance transparency.** The data existsâ€”we just need to go get it.\nEOF\n)\")",
      "Bash(git push:*)",
      "Bash(ps:*)",
      "Bash(timeout 90 curl -s \"https://taskforce-purple-itemized-prototype.dev-a4b.workers.dev/analyze\")",
      "Bash(tee:*)",
      "Bash(time curl:*)",
      "Bash(for i in 000 001 010 020 035)",
      "Bash(do echo:*)",
      "Bash(done)",
      "Bash(for chunk in 000 005 010 015 020 025 030 035)",
      "Bash(do wrangler kv key get \"transactions:S000033:chunk_$chunk\" --namespace-id=8318226115e2423ab5d141adfa5419f9 --remote)",
      "Bash(for:*)",
      "Bash(do wrangler kv key delete \"transactions:S000033:chunk_$i\" --namespace-id=8318226115e2423ab5d141adfa5419f9 --remote)",
      "Bash(timeout 60 curl -s \"https://taskforce-purple-itemized-prototype.dev-a4b.workers.dev/analyze\")",
      "Bash(echo:*)",
      "Read(//tmp/**)",
      "Bash(gh issue view:*)",
      "Bash(gh issue comment:*)",
      "Bash(wrangler tail:*)",
      "Bash(gh issue close 15 --comment \"$(cat <<''EOF''\n## âœ… FIXED AND VERIFIED (2025-10-22)\n\n### Root Cause\nMembers with `dataCycle: 1970` were stored when initial financial fetches failed. The member update logic never refreshed this field, so stale values persisted forever.\n\n### Solution Implemented\n1. **Added dataCycle refresh to 3 update locations** (commit a580ff8)\n   - PAC details updates (line 1344-1346)\n   - Financial data updates (line 2379)\n   - Enhanced PAC updates (line 3175)\n\n2. **Integrated into recalculate-tiers endpoint** (commit 8e0be91)\n   - One-call cleanup for all 537 members\n   - Removes need to reprocess individual members\n\n### Verification\n**Before**: AOC and Josh Hawley showing `dataCycle: 1970`\n**After**: 447/537 members (83%) now showing `dataCycle: 2024`\n\nRemaining 77 members with `$0 raised` are correctly skipped (no financial data to recalculate).\n\n### Usage\nTo fix all remaining members:\n```bash\ncurl -X POST \"https://taskforce-purple-api.dev-a4b.workers.dev/api/recalculate-tiers\" \\\n  -H \"Authorization: Bearer taskforce_purple_2025_update\"\n```\n\n**Status**: âœ… RESOLVED\nEOF\n)\")",
      "WebFetch(domain:www.fec.gov)",
      "WebSearch",
      "WebFetch(domain:projects.propublica.org)",
      "WebFetch(domain:www.opensecrets.org)",
      "WebFetch(domain:github.com)",
      "WebFetch(domain:developers.cloudflare.com)",
      "Bash(YESUE)",
      "Bash(MA)",
      "Bash(01740\", total: 5000 },\n  { key: \"SUSAN)",
      "Bash(M)",
      "Bash(DORKINGS)",
      "Bash(NY)",
      "Bash(awk:*)",
      "Bash(__NEW_LINE__ API_KEY=\"zVpKDAacmPcazWQxhl5fhodhB9wNUH0urLCLkkV9\" COMMITTEE_ID=\"C00411330\")",
      "Bash(__NEW_LINE__ API_KEY=\"zVpKDAacmPcazWQxhl5fhodhB9wNUH0urLCLkkV9\")",
      "Bash(COMMITTEE_ID=\"C00411330\")",
      "Bash(__NEW_LINE__ curl -s \"https://api.open.fec.gov/v1/committee/$COMMITTEE_ID/totals/?api_key=$API_KEY&cycle=2026\")",
      "Bash(__NEW_LINE__ echo \"Raw 2024 response:\")",
      "Bash(__NEW_LINE__ curl -s \"https://api.open.fec.gov/v1/schedules/schedule_a/?api_key=zVpKDAacmPcazWQxhl5fhodhB9wNUH0urLCLkkV9&committee_id=C00411330&two_year_transaction_period=2024&contributor_type=individual&per_page=100&page=1&sort=-contribution_receipt_date\")",
      "Bash(jq:*)",
      "Bash(wrangler d1 execute:*)",
      "Bash(ls:*)",
      "Bash(npm run build:*)",
      "Bash(wrangler pages deploy:*)",
      "Bash(find:*)",
      "Bash(wrangler kv namespace list:*)",
      "Bash(wrangler d1 list:*)",
      "Bash(wrangler versions list:*)",
      "Bash(git log:*)",
      "Bash(node add-members.js:*)",
      "Bash(do echo \"Run $i...\")"
    ],
    "deny": [],
    "ask": []
  }
}
